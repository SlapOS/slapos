##############################################################################
#
# Copyright (c) 2010 Vifib SARL and Contributors. All Rights Reserved.
#
# WARNING: This program as such is intended to be used by professional
# programmers who take the whole responsibility of assessing all potential
# consequences resulting from its eventual inadequacies and bugs
# End users who are looking for a ready-to-use solution with commercial
# guarantees and support are strongly adviced to contract a Free Software
# Service Company
#
# This program is Free Software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 3
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
#
##############################################################################
import logging
import json
import time
import os
import sys
import argparse
import fcntl
from six.moves.configparser import RawConfigParser
from slapos.recipe.localinstancedb import HostedInstanceLocalDB, InstanceListComparator
from slapos import slap
from slapos.recipe.librecipe.genericslap import CONNECTION_CACHE
import six

class Recipe(object):
  """
  Compare two instance databases and request instances accordingly.

  This recipe compares instances from instance-db-path (update_list) with
  instances stored in requestinstance-db-path (stored_dict) using
  InstanceListComparator. It then:
  - Requests new instances (if valid)
  - Updates modified instances (if valid)
  - Destroys instances that are no longer in the update list

  Input:
    instance-db-path
      Path to database containing the source instance list (update_list).
      This database should be generated by HostedInstanceLocalDB.

    requestinstance-db-path
      Path to database containing the stored requested instances (stored_dict).
      This database should be generated by HostedInstanceLocalDB.
      Will be updated after all requests are processed.

    server-url
    key-file (optional)
    cert-file (optional)
      Used to contact slap master.

    computer-id
    partition-id
      Current partition's identifiers.
      Must match key's credentials if given.

    software-url
      URL of a software definition to request instances of.
      Must be provided as a recipe option.

    software-type
      Software type of requested instances.
      Must be provided as a recipe option.

    shared (optional, defaults to false)
      Set to "true" when requesting shared instances.

    request-name-prefix (optional, defaults to empty string)
      Prefix to prepend to instance reference when making requests to the master.
      The prefix is only applied to the request name, not to local database references.
  """

  def __init__(self, buildout, name, options):
    self.logger = logging.getLogger(name)
    self.options = options

    # Configure logging if logfile or debug options are explicitly provided
    # This allows logging to be configured through recipe options
    # Note: Only configure if explicitly requested and not already configured
    # In main(), logging is configured before Recipe is created, so this won't run there
    logfile = options.get('logfile')
    debug_str = options.get('debug', '')
    debug = debug_str.lower() in ['y', 'yes', '1', 'true'] if debug_str else False
    # Only configure if explicitly requested (logfile is set, or debug is explicitly set to true)
    # This prevents auto-configuration in tests
    if (logfile or (debug_str and debug)):
      # Only configure if not already configured (basicConfig can only be called once effectively)
      root_logger = logging.getLogger()
      if not root_logger.handlers:
        configure_logging(logfile=logfile, debug=debug)

    # Required options
    self.instance_db_path = options['instance-db-path']
    self.requestinstance_db_path = options['requestinstance-db-path']

    # Initialize databases
    self.instance_db = HostedInstanceLocalDB(self.instance_db_path)
    self.requestinstance_db = HostedInstanceLocalDB(self.requestinstance_db_path)

    # Store request options for later use
    self.server_url = options['server-url']
    self.computer_id = options['computer-id']
    self.partition_id = options['partition-id']
    self.key_file = options.get('key-file')
    self.cert_file = options.get('cert-file')
    self.software_url = options.get('software-url')
    self.software_type = options.get('software-type')

    self.shared = options.get('shared', 'false').lower() in ['y', 'yes', '1', 'true']

    # Optional prefix for request names
    self.request_name_prefix = options.get('request-name-prefix', '')

    # Extract sla-* options from recipe options (same for all instances)
    # These will be used as filter_kw in requests
    self.sla_filter_kw = {}
    for key, value in six.iteritems(options):
      if key.startswith('sla-') and value:
        self.sla_filter_kw[key[4:]] = value  # Remove 'sla-' prefix

    # Lazy initialization of computer_partition for publishing connection parameters
    self._computer_partition = None

    # Progress tracking for periodic logging
    self._progress_start_time = None
    self._progress_last_log_time = None
    self._progress_processed_count = 0
    self._progress_total_to_process = 0

  def initialiseReportingLogging(self, total_instance_number, comparison, reprocess_number):
    """
    Initialize periodic logging tracking variables.

    Args:
      total_to_process: Total number of instances to process
    """
    self.logger.info(
      'Comparison results: %d total instances, %d added, %d removed, %d modified, %d unchanged invalid instances to process',
      total_instance_number,
      len(comparison['added']),
      len(comparison['removed']),
      len(comparison['modified']),
      reprocess_number
    )

    # Calculate total instances to process
    total_to_process = (
      len(comparison['added']) +
      len(comparison['modified']) +
      reprocess_number +
      len(comparison['removed'])
    )
    self._progress_start_time = time.time()
    self._progress_last_log_time = self._progress_start_time
    self._progress_processed_count = 0
    self._progress_total_to_process = total_to_process

  def logIfTimePassed(self):
    """
    Check if a minute has passed since last log and log progress if so.
    """
    current_time = time.time()
    if current_time - self._progress_last_log_time >= 60:
      percentage = (
        (self._progress_processed_count / self._progress_total_to_process * 100)
        if self._progress_total_to_process > 0 else 0
      )
      self.logger.info(
        'Progress: %d/%d instances processed (%.1f%%)',
        self._progress_processed_count, self._progress_total_to_process, percentage
      )
      self._progress_last_log_time = current_time

  def logFinalReport(self):
    """
    Log final summary of instance processing.
    """
    elapsed_time = time.time() - self._progress_start_time
    self.logger.info(
      'Instance node processing completed: %d instances processed in %.1f seconds',
      self._progress_processed_count, elapsed_time
    )

  def _getUpdateList(self):
    """
    Get update list from instance-db-path.
    Returns list of dicts with 'reference', 'parameters', 'valid', and 'error_info' keys.
    """
    instance_list = self.instance_db.getInstanceList("reference, json_parameters, json_error, valid_parameter")
    update_list = []
    for row in instance_list:
      try:
        parameters = json.loads(row['json_parameters']) if row['json_parameters'] else {}
        error_info = {}
        if row['json_error']:
          try:
            error_info = json.loads(row['json_error'])
          except (ValueError, TypeError):
            error_info = {}
        valid_parameter = row['valid_parameter'] if row['valid_parameter'] is not None else True
        update_list.append({
          'reference': row['reference'],
          'parameters': parameters,
          'valid': bool(valid_parameter),
          'error_info': error_info
        })
      except (ValueError, TypeError) as e:
        self.logger.warning(
          'Failed to parse json_parameters for instance %s: %s',
          row['reference'], e
        )
    return update_list

  def _getStoredDict(self):
    """
    Get stored dict from requestinstance-db-path.
    Returns dict mapping reference to hash.
    """
    stored_list = self.requestinstance_db.getInstanceList("reference, hash")
    return {row["reference"]: row["hash"] for row in stored_list}

  def _requestInstance(self, instance_reference, parameters, state=None):
    """
    Request an instance directly using the slap library.

    Args:
      instance_reference: Reference name for the instance
      parameters: Dict of parameters from the database
      state: Optional state override (e.g., 'destroyed', defaults to 'started')

    Returns:
      tuple: (valid, error_list, connection_params)
        - valid: Boolean indicating if connection parameters were successfully retrieved
        - error_list: List of error messages (empty list)
        - connection_params: Dict of connection parameters or message dict
    """
    # Get computer_partition (reuses connection cache)
    computer_partition = self._getComputerPartition()

    # Determine state (default to 'started' if not specified)
    requested_state = state if state is not None else 'started'

    # Use sla-* options from recipe options (stored in __init__)
    # These are the same for all instances
    filter_kw = self.sla_filter_kw.copy()

    # All parameters go to partition_parameter_kw
    # (sla-* options come from recipe options, not instance parameters)
    partition_parameter_kw = parameters.copy()

    # Apply request-name-prefix if specified
    request_reference = instance_reference
    if self.request_name_prefix:
      request_reference = self.request_name_prefix + instance_reference

    # Make the request directly using the slap library
    valid = False
        # software-url and software-type are mandatory and cannot be overridden
    if not self.software_url or not self.software_type:
      raise ValueError(
        'software-url and software-type are required. It must be provided as a recipe option.'
      )

    try:
      instance = computer_partition.request(
        self.software_url,
        self.software_type,
        request_reference,
        partition_parameter_kw=partition_parameter_kw,
        filter_kw=filter_kw,
        shared=self.shared,
        state=requested_state
      )

      # Get connection parameters if available
      # Note: Connection parameters are only available if the instance publishes them
      try:
        connection_params = instance.getConnectionParameterDict()
        valid = True
      except Exception as e:
        # Connection parameters may not be available yet or instance may not publish them
        self.logger.debug(
          'Could not retrieve connection parameters for instance %s: %s',
          instance_reference, e
        )

        connection_params = {
          "message": "Your instance is valid the request has been transmitted to the master"
        }

      return valid, [], connection_params
    except Exception as e:
      self.logger.error(
        'Failed to request instance %s: %s',
        instance_reference, e
      )
      raise

  def preDeployInstanceValidation(self, instance_reference, parameters):
    """
    Validate instance parameters. Can be overridden by subclasses for custom validation.

    Args:
      instance_reference: Reference name for the instance
      parameters: Dict of parameters from the database

    Returns:
      tuple: (is_valid, error_list, validation_info)
        - is_valid: Boolean indicating if validation passed
        - error_list: List of error messages (empty if valid)
        - validation_info: Dict of validation instructions or error details
    """
    # Base implementation: no validation, always valid
    return True, [], {}

  def _getComputerPartition(self):
    """
    Get or create the computer_partition object for publishing connection parameters.
    Uses CONNECTION_CACHE to reuse connections.

    Returns:
      computer_partition object

    Raises:
      KeyError: If 'slap-connection' section is missing from buildout
      Exception: If connection initialization fails
    """
    if self._computer_partition is not None:
      return self._computer_partition

    # Use connection cache
    cache_key = "%s_%s" % (self.computer_id, self.partition_id)
    self._computer_partition = CONNECTION_CACHE.get(cache_key, None)

    if self._computer_partition is None:
      # Initialize slap connection
      slap_instance = slap.slap()
      slap_instance.initializeConnection(self.server_url, self.key_file, self.cert_file)
      self._computer_partition = slap_instance.registerComputerPartition(
        self.computer_id,
        self.partition_id
      )
      CONNECTION_CACHE[cache_key] = self._computer_partition

    return self._computer_partition

  def _shouldPublishInformation(self, instance_reference, publish_information):
    """
    Check if publish_information should be published by comparing with stored json_error.

    Args:
      instance_reference: Reference name for the instance
      publish_information: Dict of information to publish (connection parameters or error info)

    Returns:
      True if information should be published (different from stored), False otherwise
    """
    if not publish_information:
      return False

    # Check if we've already published the same information
    # by comparing with what's stored in the database
    try:
      stored_instance = self.requestinstance_db.getInstance(instance_reference)
      try:
        stored_info = json.loads(stored_instance['json_error'])
        # Compare dictionaries (order-independent comparison)
        if stored_info == publish_information:
          self.logger.debug(
            'Information for instance %s unchanged, skipping publish',
            instance_reference
          )
          return False
      except (ValueError, TypeError):
        # If json_error can't be parsed, treat as different and publish
        pass
    except Exception as e:
      # If we can't retrieve stored instance, log and continue with publish
      self.logger.debug(
        'Could not retrieve stored instance %s for comparison: %s',
        instance_reference, e
      )

    return True

  def publishInstanceInformation(self, instance_reference, publish_information):
    """
    Publish instance information (connection parameters) for a successfully deployed instance.
    Called when an instance has been successfully deployed and validated.
    Can be overridden by subclasses to customize information publishing behavior.

    Args:
      instance_reference: Reference name for the instance
      publish_information: Dict of connection parameters or instance information
    """
    # Check if we need to publish (information has changed)
    if not self._shouldPublishInformation(instance_reference, publish_information):
      return

    # Publish connection parameters
    self._publishConnectionParameters(instance_reference, publish_information)

  def publishInstanceErrorInformation(self, instance_reference, publish_information):
    """
    Publish error/validation information for an instance.
    Called when an instance fails validation or deployment.
    Can be overridden by subclasses to customize error publishing behavior.

    Args:
      instance_reference: Reference name for the instance
      publish_information: Dict of error information or validation instructions
    """
    # Check if we need to publish (information has changed)
    if not self._shouldPublishInformation(instance_reference, publish_information):
      return

    # Publish connection parameters (error information)
    self._publishConnectionParameters(instance_reference, publish_information)

    # Also call computer_partition.error() to notify the master about the error
    try:
      computer_partition = self._getComputerPartition()
      computer_partition.error(publish_information, slave_reference=instance_reference)
      self.logger.debug(
        'Published error information for instance %s',
        instance_reference
      )
    except Exception as e:
      self.logger.warning(
        'Failed to publish error information for instance %s: %s',
        instance_reference, e
      )

  def _publishConnectionParameters(self, instance_reference, conn_params):
    """
    Internal method to publish connection parameters for an instance using the slap library.
    Parameters are published to the SlapOS master for the specified slave instance.
    This method does not check if information has changed - that check should be done
    by the caller (publishInstanceInformation or publishInstanceErrorInformation).

    Args:
      instance_reference: Reference name for the instance (used as slave_reference)
      conn_params: Dict of connection parameters or validation instructions
    """
    if not conn_params:
      return

    try:
      computer_partition = self._getComputerPartition()
      computer_partition.setConnectionDict(conn_params, slave_reference=instance_reference)
      self.logger.debug(
        'Published connection parameters for instance %s',
        instance_reference
      )
    except Exception as e:
      self.logger.warning(
        'Failed to publish connection parameters for instance %s: %s',
        instance_reference, e
      )

  def updateInstanceInDB(self, instance_reference, instance_data, instance_hash, publish_information, instance_needs_reprocessing, is_new=False):
    """
    Update an existing instance in requestinstance-db-path.
    Called after each successful request or when tracking invalid instances.

    Args:
      instance_reference: Reference name for the instance
      instance_data: Dict with 'parameters' and 'valid' keys
      instance_hash: Hash of the instance data
      publish_information: Information Published to the master for the instance
      instance_needs_reprocessing: Boolean indicating if the instance needs reprocessing
    """
    params_json = json.dumps(instance_data['parameters'], sort_keys=True)
    timestamp = str(int(time.time()))
    # Store validation_info (connection parameters or error info) in json_error
    # This allows us to compare and avoid republishing unchanged connection parameters
    error_json = json.dumps(publish_information, sort_keys=True) if publish_information else "{}"
    is_valid = not instance_needs_reprocessing # if the instance needs reprocessing, it is not valid
    if not is_new:
      update_instance_list = [(
        params_json,
        error_json,
        instance_hash,
        timestamp,
        is_valid,
        instance_reference
      )]
      update_query = (
        "UPDATE instance SET json_parameters = ?, "
        "json_error = ?, hash = ?, timestamp = ?, "
        "valid_parameter = ? WHERE reference = ?"
      )
      self.requestinstance_db.updateInstanceList(update_query, update_instance_list)
    else:
      new_instance_list = [(
        instance_reference,
        params_json,
        error_json,
        instance_hash,
        timestamp,
        is_valid
      )]
      self.requestinstance_db.insertInstanceList(new_instance_list)

  def _removeInstanceFromDB(self, instance_reference):
    """
    Remove an instance from requestinstance-db-path.
    Called after each successful destroy request.

    Args:
      instance_reference: Reference name for the instance
    """
    self.requestinstance_db.removeInstanceList([instance_reference])

  def deployInstance(self, instance_reference, instance_data):
    """
    Deploy an instance.
    """
    try:
      valid, error_list, connection_parameters = self._requestInstance(
        instance_reference,
        instance_data
      )
      # Get connection parameters from the request result
      return valid, error_list, connection_parameters
    except Exception as e:
      self.logger.error(
        'Failed to request instance %s: %s',
        instance_reference, e
      )
      return False, ['Failed to deploy instance'], {}

  def postDeployInstanceValidation(self, instance_reference, instance_data, publish_information):
    """
    Validate the instance after it has been deployed.
    """
    if not publish_information:
      return False, [], {
          "message": "Your instance is valid the request has been transmitted to the master, waiting for its connection parameters"
        }
    return True, [], publish_information

  def _processInstance(self, instance_reference, instance_data, instance_hash, is_new=False):
    """
    Process a single instance: validate, request if valid, and publish results.

    Args:
      instance_reference: Reference name for the instance
      instance_data: Dict with 'parameters', 'valid', and 'error_info' keys
      instance_hash: Hash of the instance data
      is_new: True if this is a new instance, False if modified

    Returns:
      True if instance was successfully processed, False if validation failed
    """
    instance_needs_reprocessing = True
    continue_processing = True
    publish_information = {}
    # Check if the paramters were validated against the JSON Schema
    parameters_passed_initial_validation = instance_data.get('valid', True)
    if not parameters_passed_initial_validation:
      publish_information = instance_data.get('error_info', {})
      if not publish_information:
        publish_information = {
          "message": "Instance validation failed"
        }
      continue_processing = False

    # Check Pre Deployments Constraints
    if continue_processing:
      is_valid, error_list, validation_info = self.preDeployInstanceValidation(
        instance_reference,
        instance_data['parameters']
      )
      continue_processing = is_valid
      publish_information = validation_info

    # Deploy the instance
    if continue_processing:
      is_valid, error_list, connection_parameters = self.deployInstance(instance_reference, instance_data['parameters'])
      continue_processing = is_valid
      publish_information = connection_parameters

    # Check Post Deployments Constraints
    if continue_processing:
      is_valid, error_list, post_deploy_information = self.postDeployInstanceValidation(instance_reference, instance_data['parameters'], publish_information)
      instance_needs_reprocessing = not is_valid
      publish_information = post_deploy_information

    if instance_needs_reprocessing:
      self.logger.debug(
        'Instance %s failed validation and needs reprocessing: %s',
        instance_reference, publish_information
      )
      # Publish error information when instance needs reprocessing
      self.publishInstanceErrorInformation(instance_reference, publish_information)
    else:
      # Publish connection parameters only when post-deploy checks are successful
      self.publishInstanceInformation(instance_reference, publish_information)

    # Add or update the instance in the database
    self.updateInstanceInDB(instance_reference, instance_data, instance_hash, publish_information, instance_needs_reprocessing, is_new)


  def _processDestroyedInstance(self, instance_reference):
    """
    Process a destroyed instance: request the destroy and remove it from the database.
    """
    self.logger.debug('Destroying instance: %s', instance_reference)
    try:
      request_result = self._requestInstance(instance_reference, {}, state='destroyed')
      # The request is already made, no need to call install()
      self._removeInstanceFromDB(instance_reference)
    except Exception as e:
      self.logger.error(
        'Failed to destroy instance %s: %s',
        instance_reference, e
      )
      raise

  def install(self):
    """
    Compare databases, make requests, and update requestinstance-db-path.
    """
    self.logger.info('Starting instance node processing')
    # Get the full list of instance from instance-db-path
    # this list is the list of instance we got from master
    update_list = self._getUpdateList()

    # Get list of stored instance reference and their hash from requestinstance-db-path
    stored_dict = self._getStoredDict()

    # Compare using InstanceListComparator
    # and return the new instances, the instances that are removed and the instances that are modified
    comparator = InstanceListComparator(update_list, stored_dict)
    comparison = comparator.compare()

    # Create mapping of reference to instance data
    instance_map = {item['reference']: item for item in update_list}
    computed_hashes = comparator.update_dict

    # Get all instances that need processing:
    # 1. New instances (added)
    # 2. Modified instances
    # 3. Previously invalid instances (even if unchanged, they need re-validation)
    # 4. Removed instances (they need to be destroyed)

    unchanged_invalid_instances_to_process = set()
    invalid_instance_rows = self.requestinstance_db.getInstanceList("reference", invalid_only=True)
    for row in invalid_instance_rows:
      if row["reference"] not in comparison['modified'] and row["reference"] not in comparison['removed']:
        unchanged_invalid_instances_to_process.add(row["reference"])

    # Initialize reporting logging
    self.initialiseReportingLogging(
      len(update_list),
      comparison,
      len(unchanged_invalid_instances_to_process)
    )

    # Process new instances
    for instance_reference in comparison['added']:
      instance_data = instance_map[instance_reference]
      instance_hash = computed_hashes[instance_reference]
      self._processInstance(instance_reference, instance_data, instance_hash, is_new=True)
      self._progress_processed_count += 1
      self.logIfTimePassed()

    # Process modified instances and unchanged invalid instances
    for instance_reference in set(comparison['modified']) | unchanged_invalid_instances_to_process:
      instance_data = instance_map[instance_reference]
      instance_hash = computed_hashes[instance_reference]
      self._processInstance(instance_reference, instance_data, instance_hash, is_new=False)
      self._progress_processed_count += 1
      self.logIfTimePassed()

    # Destroy removed instances
    for instance_reference in comparison['removed']:
      self._processDestroyedInstance(instance_reference)
      self._progress_processed_count += 1
      self.logIfTimePassed()

    # Log final summary
    self.logFinalReport()
    self.logger.info('================================================================================')
    return []

  update = install


class PIDFileLock(object):
  """
  Context manager for PID file locking to prevent multiple instances.
  """
  def __init__(self, pidfile_path):
    self.pidfile_path = pidfile_path
    self.pidfile = None

  def __enter__(self):
    if not self.pidfile_path:
      return self
    try:
      # Create directory if it doesn't exist
      pidfile_dir = os.path.dirname(self.pidfile_path)
      if pidfile_dir and not os.path.exists(pidfile_dir):
        os.makedirs(pidfile_dir)

      # Open PID file in append mode (create if doesn't exist)
      self.pidfile = open(self.pidfile_path, 'a+')

      # Try to acquire exclusive lock (non-blocking)
      fcntl.flock(self.pidfile.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)

      # Write current PID to file
      self.pidfile.seek(0)
      self.pidfile.truncate()
      self.pidfile.write(str(os.getpid()) + '\n')
      self.pidfile.flush()

      return self
    except (IOError, OSError) as e:
      if self.pidfile:
        self.pidfile.close()
        self.pidfile = None
      # Check if another process is running
      if os.path.exists(self.pidfile_path):
        try:
          with open(self.pidfile_path, 'r') as f:
            old_pid = f.read().strip()
            if old_pid:
              # Check if process is still running
              try:
                os.kill(int(old_pid), 0)
                raise SystemExit(
                  'Another instance is already running (PID: %s). '
                  'If this is not the case, remove the PID file: %s'
                  % (old_pid, self.pidfile_path)
                )
              except (OSError, ValueError):
                # Process doesn't exist, remove stale PID file
                os.remove(self.pidfile_path)
                # Retry lock acquisition
                return self.__enter__()
        except (IOError, ValueError):
          pass
      raise SystemExit('Failed to acquire lock on PID file %s: %s' % (self.pidfile_path, e))

  def __exit__(self, exc_type, exc_val, exc_tb):
    if self.pidfile:
      try:
        fcntl.flock(self.pidfile.fileno(), fcntl.LOCK_UN)
      except (IOError, OSError):
        pass
      self.pidfile.close()
      # Remove PID file on successful exit
      if exc_type is None and self.pidfile_path and os.path.exists(self.pidfile_path):
        try:
          os.remove(self.pidfile_path)
        except (IOError, OSError):
          pass


def parse_config_file(config_path):
  """
  Parse a buildout-style config file and return a ConfigParser object.

  Args:
    config_path: Path to the config file

  Returns:
    RawConfigParser object with parsed config
  """
  if not os.path.exists(config_path):
    raise SystemExit('Config file does not exist: %s' % config_path)

  parser = RawConfigParser()
  parser.read(config_path)
  return parser


def get_config_section(parser, section_name):
  """
  Get a section from the config parser as a dictionary.

  Args:
    parser: RawConfigParser object
    section_name: Name of the section to retrieve

  Returns:
    Dictionary of section options, or empty dict if section doesn't exist
  """
  if not parser.has_section(section_name):
    return {}

  options = {}
  for key, value in parser.items(section_name):
    options[key] = value
  return options





def create_options_dict_from_config(config_parser, section_name='slaposinstancenode'):
  """
  Create options dictionary from config file section.

  Args:
    config_parser: RawConfigParser object with parsed config
    section_name: Name of the section to read options from (default: 'slaposinstancenode')

  Returns:
    Dictionary of options
  """
  options = get_config_section(config_parser, section_name)

  if not options:
    raise SystemExit('Config file must contain a [%s] section' % section_name)

  return options


def configure_logging(logfile=None, debug=False):
  """
  Configure logging to file or stderr.

  Args:
    logfile: Optional path to log file. If None, logs go to stderr.
    debug: If True, set log level to DEBUG. Otherwise, set to INFO.
  """
  # Remove existing handlers to avoid duplicates
  root_logger = logging.getLogger()
  for handler in root_logger.handlers[:]:
    root_logger.removeHandler(handler)

  # Set log level
  log_level = logging.DEBUG if debug else logging.INFO
  root_logger.setLevel(log_level)

  # Create handler
  if logfile:
    # Create directory if it doesn't exist
    logfile_dir = os.path.dirname(logfile)
    if logfile_dir and not os.path.exists(logfile_dir):
      os.makedirs(logfile_dir, exist_ok=True)
    handler = logging.FileHandler(logfile)
  else:
    handler = logging.StreamHandler(sys.stderr)

  # Set formatter
  formatter = logging.Formatter(
    '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  )
  handler.setFormatter(formatter)
  handler.setLevel(log_level)

  # Add handler to root logger
  root_logger.addHandler(handler)


def parse_command_line_args():
  """
  Parse command-line arguments for config file path, PID file, logfile, and debug.

  Returns:
    argparse.Namespace with cfg, pidfile, logfile, and debug attributes
  """
  parser = argparse.ArgumentParser(
    description='Request Instance List Recipe - Command line interface',
    formatter_class=argparse.RawDescriptionHelpFormatter
  )

  parser.add_argument(
    '--cfg',
    required=True,
    help='Path to configuration file (slaposinstancenode.cfg)'
  )

  parser.add_argument(
    '--pidfile',
    help='Path to PID file to prevent multiple instances (optional)'
  )

  parser.add_argument(
    '--logfile',
    help='Path to log file (optional). If not specified, logs go to stderr.'
  )

  parser.add_argument(
    '--debug',
    action='store_true',
    help='Enable debug logging'
  )

  return parser.parse_args()


def load_config_and_create_objects(config_path, pidfile_path=None, section_name='slaposinstancenode'):
  """
  Load config file, handle PID file locking, and create options dict.

  Args:
    config_path: Path to config file
    pidfile_path: Optional path to PID file
    section_name: Name of the section to read from config (default: 'slaposinstancenode')

  Returns:
    tuple: (options_dict, pidfile_lock_context)
    The pidfile_lock_context should be used as a context manager
  """
  # Parse config file
  config_parser = parse_config_file(config_path)

  # Get options from config
  options = create_options_dict_from_config(config_parser, section_name)

  # Create PID file lock context
  pidfile_lock = PIDFileLock(pidfile_path) if pidfile_path else None

  return options, pidfile_lock


def main():
  """
  Main entry point for command-line execution.
  """
  try:
    # Parse command-line arguments
    args = parse_command_line_args()

    # Load config file and create options dict with PID file locking
    options, pidfile_lock = load_config_and_create_objects(
      args.cfg,
      args.pidfile,
      section_name='slaposinstancenode'
    )

    # Configure logging
    # Command line arguments take precedence over config file options
    logfile = args.logfile or options.get('logfile')
    debug = args.debug or options.get('debug', 'false').lower() in ['y', 'yes', '1', 'true']
    configure_logging(logfile=logfile, debug=debug)

    # Use PID file lock as context manager to prevent multiple instances
    if pidfile_lock:
      with pidfile_lock:
        # Create recipe instance
        recipe = Recipe(
          buildout=None,
          name='request-instance-list',
          options=options
        )

        # Run the recipe
        recipe.install()
    else:
      # No PID file locking
      # Create recipe instance
      recipe = Recipe(
        buildout=None,
        name='request-instance-list',
        options=options
      )

      # Run the recipe
      recipe.install()

    return 0
  except KeyboardInterrupt:
    sys.stderr.write('\nInterrupted by user\n')
    return 130
  except SystemExit as e:
    # Re-raise SystemExit to preserve exit code
    raise
  except Exception as e:
    sys.stderr.write('Error: %s\n' % str(e))
    import traceback
    traceback.print_exc()
    return 1


if __name__ == '__main__':
  sys.exit(main())

