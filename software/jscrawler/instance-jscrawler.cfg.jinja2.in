{% set part_list = [] -%}

[directory]
recipe = slapos.cookbook:mkdirectory
etc = ${buildout:directory}/etc
bin = ${buildout:directory}/bin
srv = ${buildout:directory}/srv
var = ${buildout:directory}/var
run = ${:var}/run
log = ${:var}/log
scripts = ${:etc}/run
services = ${:etc}/service
plugins = ${:etc}/plugin
ssl = ${:etc}/ssl
www = ${:srv}/www
tmp = ${:srv}/tmp


#################################
# Nginx service
#################################
[httpd-wrapper]
recipe = slapos.cookbook:simplehttpserver
host = {{ (ipv6 | list)[0] }}
port = 9083
base-path = ${directory:www}
wrapper = ${directory:services}/http-server
log-file = ${directory:log}/httpd.log
use-hash-url = false

[request-jscrawler-frontend]
<= slap-connection
recipe = slapos.cookbook:requestoptional
name = jscawler Frontend
# XXX We have hardcoded SR URL here.
software-url = http://git.erp5.org/gitweb/slapos.git/blob_plain/HEAD:/software/apache-frontend/software.cfg
slave = true
config-url = http://[${httpd-wrapper:host}]:${httpd-wrapper:port}
return = site_url domain

[jscrawler-frontend-promise]
<= monitor-promise-base
module = check_url_available
name = jscrawler_frontend.py
config-url = ${request-jscrawler-frontend:connection-site_url}
config-check-secure = 1


{%  do part_list.append('logrotate-entry-httpd') -%}
[logrotate-entry-httpd]
<= logrotate-entry-base
name = http-server
log = ${httpd-wrapper:log-file}


[httpd-listen-promise]
<= monitor-promise-base
module = check_port_listening
name = httpd-listen.py
config-hostname = ${httpd-wrapper:host}
config-port = ${httpd-wrapper:port}

[jscrawler-wrapper]
recipe = slapos.cookbook:wrapper
command-line =
  {{ parameter_dict['nodejs-location'] }} {{ parameter_dict['jscrawler-location'] }} 
wrapper-path = ${directory:bin}/jscrawler

{% set url_list = slapparameter_dict.get('urls', "") -%}
{% set site_list = [] %}
{% for l in url_list.split() %}
{%   do site_list.extend(l.split(',')) %}
{% endfor -%}
[jscrawler-build-wrapper]
recipe = slapos.recipe.template:jinja2
template = {{ parameter_dict['template-jscrawler'] }}
rendered = ${directory:bin}/jscrawler-build
extensions = jinja2.ext.do
mode = 0700
list = {{ site_list | join(' ') }}
period = {{ slapparameter_dict.get('crawl-periodicity', 0) }}
context =
  key public_folder directory:www
  key tmp_folder directory:tmp
  key jscrawler_wrapper jscrawler-wrapper:wrapper-path
  key period :period
  key url_list :list
  raw shell_binary {{ bash_executable_location }}
  raw pid_file ${directory:run}/jscrawler.pid

[cron-entry-build-sitemap]
<= cron
recipe = slapos.cookbook:cron.d
name = jscrawler-build
frequency = */1 * * * *
command = ${jscrawler-build-wrapper:rendered}


[publish-connection-information]
<= monitor-publish
recipe = slapos.cookbook:publish
url = ${request-jscrawler-frontend:connection-site_url}
backend-url = http://[${httpd-wrapper:host}]:${httpd-wrapper:port}

[buildout]
extends = {{ template_monitor }}

parts =
  publish-connection-information
# Complete parts with sections
  {{ part_list | join('\n  ') }}
# nginx and crawler cron
  cron-entry-build-sitemap
  httpd-wrapper
  httpd-listen-promise
  jscrawler-frontend-promise

eggs-directory = {{ eggs_directory }}
develop-eggs-directory = {{ develop_eggs_directory }}
offline = true
