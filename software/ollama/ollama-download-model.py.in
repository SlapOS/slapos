#!/usr/bin/env python3
import os
import sys
import subprocess
import logging
import time
import hashlib

# Setup logging
log_file = "{{ directory_log }}/ollama-model-download.log"
logging.basicConfig(
    filename=log_file,
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Check if model_name already installed by ollama
def ollama_has_model(model_name, env):
    try:
        out = subprocess.check_output(['{{ ollama_instance_location }}/ollama', 'list'], env=env, text=True)
    except subprocess.CalledProcessError as e:
        # if ollama list failed, no model was downloaded
        return False
    # skip the first line, then check the coloumn one
    # NAME               ID              SIZE      MODIFIED
    # deepseek-r1:14b    ea35dfe18182    9.0 GB    15 hours ago
    for line in out.splitlines()[1:]:
        parts = line.split()
        if parts and parts[0] == model_name:
            return True
    return False

def main():
    if len(sys.argv) != 4:
        print(f"Usage: {sys.argv[0]} <config_file> <processed_file> <error_file>")
        return 1

    config_file, processed_file, error_file = sys.argv[1:]
    logging.info("Starting to handle the model")

    # Read model name from config
    try:
        with open(config_file, 'r') as f:
            model_name = f.read().strip()
    except Exception as e:
        logging.error("Failed to read config file: %s", str(e))
        return 1
    logging.info(f"Model name {model_name}")
    # Ensure model directory exists
    models_dir = "{{ directory_models }}"
    os.makedirs(models_dir, exist_ok=True)

    # Set environment variables
    env = os.environ.copy()
    env['OLLAMA_MODELS'] = models_dir

    logging.info(f"Checking {model_name} is exist")
    # Check if the model already downloaded
    try:
        if ollama_has_model(model_name, env):
            logging.info(f"{model_name} is exist")
            with open(error_file, 'w+') as ef:
                ef.write(f"INF: {model_name} : already downloaded\n")
            # Mark it was downloaded
            with open(processed_file, 'w') as pf:
                pf.write(model_name)
            sys.exit(0)
        else:
            logging.info(f"{model_name} not exist, download it")
            with open(error_file, 'w') as ef:
                ef.write("INF: Download in progress\n")
    except Exception as e:
        logging.error("Failed to open error file: %s", str(e))

    # Download the model with model_name
    try:
        logging.info(f"Starting download of model: {model_name}")
        start_time = time.time()

        process = subprocess.Popen(
            ["{{ ollama_instance_location }}/ollama", 'pull', model_name],
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )

        # Log download progress
        for line in iter(process.stdout.readline, ''):
            logging.info(line.strip())
            sys.stdout.write(line)
            sys.stdout.flush()

        process.stdout.close()
        return_code = process.wait()

        end_time = time.time()
        duration = end_time - start_time

        if return_code == 0:
            logging.info(f"Model {model_name} downloaded successfully in {duration:.2f} seconds")
        else:
            logging.error(f"Model download failed with return code: {return_code}")
    except Exception as e:
        logging.error(f"Error during model download: {str(e)}")

    # Download successfully, make sure it can be read by ollama list
    logging.info(f"Make sure model {model_name} can be read by ollama list")
    if ollama_has_model(model_name, env):
        # Mark it as complished
        with open(processed_file, 'w') as pf:
            pf.write(model_name)
            logging.info(f"Write model {model_name} to processed file")
        # empty error_file, means there is no error
        open(error_file, 'w').close()
        return 0
    else:
        with open(error_file, 'w+') as ef:
            ef.write("ERR: Download reported success but model not found locally\n")
        return 1

if __name__ == "__main__":
    sys.exit(main())
