#!/usr/bin/env python3
import os
import sys
import subprocess
import logging
import time
import hashlib

# Setup logging
log_file = "{{ directory_log }}/ollama-model-download.log"
logging.basicConfig(
    filename=log_file,
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# Check if model_name already installed by ollama
def ollama_has_model(model_name, env):
    logging.info("In the ollama_has_model")
    try:
        out = subprocess.check_output(["{{ ollama_location }}/ollama", "list"], env=env, text=True)
    except subprocess.CalledProcessError as e:
        # if ollama list failed, no model was downloaded
        logging.info(f"Ollama checkinf failed: {e}")
        return False
    # skip the first line, then check the coloumn one
    # NAME                                ID              SIZE      MODIFIED
    # deepseek-r1:14b                     ea35dfe18182    9.0 GB    25 hours ago
    # steamdj/llama3.1-cpu-only:latest    9497a3e04b1b    4.7 GB    19 seconds ago
    # qwen3:0.6b                          3bae9c93586b    522 MB    2 hours ago
    logging.info("Get the result of ollama list")
    for line in out.splitlines()[1:]:
        parts = line.split()
        if parts and model_name in parts[0]:
            logging.info("Found the model")
            return True
    logging.info("Didn't found the model")
    return False

def main():
    if len(sys.argv) != 4:
        print(f"Usage: {sys.argv[0]} <config_file> <processed_file> <error_file>")
        return 1

    config_file, processed_file, error_file = sys.argv[1:]
    logging.info("Starting to handle the model")

    # Read model name from config
    try:
        with open(config_file, 'r') as f:
            model_name = f.read().strip()
    except Exception as e:
        logging.error("Failed to read config file: %s", str(e))
        return 1
    logging.info(f"Model name {model_name}")
    # Ensure model directory exists
    models_dir = "{{ directory_models }}"
    os.makedirs(models_dir, exist_ok=True)

    # Set environment variables
    env = os.environ.copy()
    env['OLLAMA_MODELS'] = models_dir
    env['OLLAMA_HOST'] = "{{ ollama_host }}"

    logging.info(f"Checking {model_name} is exist")
    # Check if the model already downloaded
    try:
        if ollama_has_model(model_name, env):
            logging.info(f"{model_name} is exist")
            with open(error_file, 'w+') as ef:
                ef.write(f"INF: {model_name} : already downloaded\n")
            # Mark it was downloaded
            with open(processed_file, 'w') as pf:
                pf.write(model_name)
            sys.exit(0)
        else:
            logging.info(f"{model_name} not exist, download it")
            with open(error_file, 'w') as ef:
                ef.write("INF: Download in progress\n")
    except Exception as e:
        logging.error("Failed to open error file: %s", str(e))

    # Download the model with model_name
    try:
        logging.info(f"Starting download of model: {model_name}")
        start_time = time.time()

        process = subprocess.Popen(
            ["{{ ollama_location }}/ollama", 'pull', model_name],
            env=env,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )

        # Log download progress
        for line in iter(process.stdout.readline, ''):
            logging.info(line.strip())
            sys.stdout.write(line)
            sys.stdout.flush()

        process.stdout.close()
        return_code = process.wait()

        end_time = time.time()
        duration = end_time - start_time

        if return_code == 0:
            logging.info(f"Model {model_name} downloaded successfully in {duration:.2f} seconds")
        else:
            logging.error(f"Model download failed with return code: {return_code}")
    except Exception as e:
        logging.error(f"Error during model download: {str(e)}")

    # Download successfully, make sure it can be read by ollama list
    logging.info(f"Make sure model {model_name} can be read by ollama list")
    if ollama_has_model(model_name, env):
        # Mark it as complished
        with open(processed_file, 'w') as pf:
            pf.write(model_name)
            logging.info(f"Write model {model_name} to processed file")
        # empty error_file, means there is no error
        open(error_file, 'w').close()
        return 0
    else:
        with open(error_file, 'w+') as ef:
            ef.write("ERR: Download reported success but model not found locally\n")
        return 1

if __name__ == "__main__":
    sys.exit(main())
