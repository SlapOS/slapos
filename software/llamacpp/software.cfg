[buildout]
extends =
  buildout.hash.cfg
  ../../stack/slapos.cfg
  ../../stack/monitor/buildout.cfg
  ../../component/cmake/buildout.cfg
  ../../component/curl/buildout.cfg
  ../../component/git/buildout.cfg
  ../../component/golang/buildout.cfg
  ../../component/gcc/buildout.cfg
  ../../component/nginx/buildout.cfg
  ../../component/openssl/buildout.cfg

parts =
  huggingface-cli
  cmake
  curl
  git
  gcc-12.3
  openssl
  software.json
  instance-input.json
  instance-default
  llama-source
  prebaked-hf-download-script
  prebaked-hf-download
  instance.cfg
  slapos-cookbook

[versions]
fsspec = 2023.5.0
tqdm = 4.42.1
huggingface-hub = 0.30

[huggingface-cli]
recipe = zc.recipe.egg
eggs =
  fsspec
  tqdm
  huggingface_hub
scripts =
  huggingface-cli

[llama-source]
recipe = slapos.recipe.build:gitclone
repository = https://github.com/ggerganov/llama.cpp.git
branch = master
git-clone-depth = 1
location = ${buildout:parts-directory}/llama.cpp
revision = fb15d649ed14ab447eeab911e0c9d21e35fb243e

[prebaked-model]
repo_id  = unsloth/embeddinggemma-300m-GGUF
filename = embeddinggemma-300m-Q4_0.gguf
destdir   = ${llama-source:location}/prebaked-models
cachedir  = ${llama-source:location}/hf-cache
log_file  = ${:destdir}/hf-download.log
state_file= ${:destdir}/huggingface-model-download.state

[prebaked-hf-download-script]
recipe = slapos.recipe.template:jinja2
url = ${:_profile_base_location_}/templates/huggingface-cli-download.py.in
output = ${llama-source:location}/bin/prebaked-hf-download.py
mode = 0755
context =
  raw hfc_bin    ${buildout:bin-directory}/huggingface-cli
  raw models_dir ${prebaked-model:destdir}
  raw cache_dir  ${prebaked-model:cachedir}
  raw log_file   ${prebaked-model:log_file}
  raw state_file ${prebaked-model:state_file}
  raw repo_id    ${prebaked-model:repo_id}
  raw filename   ${prebaked-model:filename}
  raw prebaked_repo_id  ""
  raw prebaked_filename ""
  raw prebaked_dir      ""

[prebaked-hf-download]
recipe = plone.recipe.command
command = ${prebaked-hf-download-script:output}
update-command = ${:command}
stop-on-error = true

[directory]
recipe = slapos.recipe.build:mkdirectory
json-schema = ${buildout:directory}/json-schema

[download-base]
recipe = slapos.recipe.build:download
url = ${:_profile_base_location_}/${:filename}

[download-json-base]
recipe = slapos.recipe.build:download
url = ${:_profile_base_location_}/${:filename}
destination = ${directory:json-schema}/${:filename}

[template-base]
recipe = slapos.recipe.template
url = ${:_profile_base_location_}/${:filename}

[software.json]
<= download-json-base

[instance-input.json]
<= download-json-base

[instance-default]
<= template-base
output = ${buildout:directory}/instance-default.cfg.jinja

[download-file]
recipe = slapos.recipe.build:download
url = ${:_profile_base_location_}/${:_update_hash_filename_}
destination = ${buildout:directory}/${:_buildout_section_name_}

[nginx.conf.in]
<= download-file

[instance.cfg]
recipe = slapos.recipe.template
url = ${:_profile_base_location_}/instance.cfg.in
output = ${buildout:directory}/instance.cfg

[huggingface-cli-download-template]
recipe = slapos.recipe.template
url = ${:_profile_base_location_}/templates/huggingface-cli-download.py.in
output = ${buildout:directory}/bin/huggingface-cli-download-template
mode = 0755

[llamacpp-server-run-template]
recipe = slapos.recipe.template
url = ${:_profile_base_location_}/templates/llamacpp-server-run.py.in
output = ${buildout:directory}/bin/llamacpp-server-run-template
mode = 0755
