[buildout]
extends = software.cfg
parts +=
  llama-build-cuda

# host machine need to have /usr/local/cuda
[llama-build-cuda]
recipe = slapos.recipe.cmmi
path = ${llama-source:location}
configure-command = ${cmake:location}/bin/cmake
configure-options =
  -B build -DGGML_CUDA=ON
make-binary =  ${cmake:location}/bin/cmake
make-targets =
  --build build --config Release
environment =
  CMAKE_INCLUDE_PATH=${curl:location}/include
  CMAKE_LIBRARY_PATH=${curl:location}/lib
  PATH=${curl:location}/bin:/usr/local/cuda/bin:${buildout:bin-directory}:%(PATH)s
  CC=gcc
  CXX=g++
  LD_LIBRARY_PATH=/usr/local/cuda/lib64:$(LD_LIBRARY_PATH)s
  LDFLAGS=-L${curl:location}/lib -Wl,-rpath=${curl:location}/lib
