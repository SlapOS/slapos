[buildout]
extends = software.cfg
parts +=
  llama-build-cuda

# host machine need to have /usr/local/cuda
[llama-build-cuda]
<= llama-build
configure-options =
  -B build -DGGML_CUDA=ON
environment =
  CMAKE_INCLUDE_PATH=${curl:location}/include
  CMAKE_LIBRARY_PATH=${curl:location}/lib
  PATH=${curl:location}/bin:/usr/local/cuda/bin:${buildout:bin-directory}:%(PATH)s
  CC=gcc
  CXX=g++
  LD_LIBRARY_PATH=/usr/local/cuda/lib64:$(LD_LIBRARY_PATH)s
  LDFLAGS=-L${curl:location}/lib -Wl,-rpath=${curl:location}/lib
